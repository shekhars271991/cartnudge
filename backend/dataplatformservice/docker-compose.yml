services:
  # ==========================================================================
  # MongoDB - Config Metadata Store
  # ==========================================================================
  mongodb:
    image: mongo:7.0
    container_name: dataplatform-mongodb
    environment:
      MONGO_INITDB_ROOT_USERNAME: cartnudge
      MONGO_INITDB_ROOT_PASSWORD: cartnudge_dev
      MONGO_INITDB_DATABASE: dataplatform
    ports:
      - "27018:27017"
    volumes:
      - dataplatform_mongodb_data:/data/db
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ==========================================================================
  # Kafka with KRaft (no Zookeeper required)
  # ==========================================================================
  kafka:
    image: confluentinc/cp-kafka:7.7.7
    container_name: dataplatform-kafka
    ports:
      - "9092:9092"   # External access from host
      - "29092:29092" # Internal access (for docker containers)
    environment:
      # KRaft settings
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      # Listeners
      KAFKA_LISTENERS: INTERNAL://:29092,EXTERNAL://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:29092,EXTERNAL://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      # Other settings
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      # KRaft cluster ID
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
    volumes:
      - dataplatform_kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list"]
      interval: 10s
      timeout: 10s
      retries: 5

  # Kafka topic initialization (backup - topics are also created by the app on startup)
  # Topics are configured in: data/event_topics.json
  kafka-init:
    image: confluentinc/cp-kafka:7.7.7
    container_name: dataplatform-kafka-init
    depends_on:
      kafka:
        condition: service_healthy
    entrypoint: ["/bin/bash", "-c"]
    command: |
      "
      echo 'Kafka is ready. Topics will be created by the application on startup.'
      echo 'See data/event_topics.json for topic configuration.'
      kafka-topics --bootstrap-server kafka:29092 --list
      "
    restart: "no"

  # ==========================================================================
  # ClickHouse - Event Store (Raw Events for Feature Engineering)
  # ==========================================================================
  clickhouse:
    image: clickhouse/clickhouse-server:24.8
    container_name: dataplatform-clickhouse
    ports:
      - "8123:8123"   # HTTP interface
      - "9000:9000"   # Native TCP interface
    environment:
      CLICKHOUSE_DB: events
      CLICKHOUSE_USER: cartnudge
      CLICKHOUSE_PASSWORD: cartnudge_dev
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
    volumes:
      - dataplatform_clickhouse_data:/var/lib/clickhouse
      - ./data/clickhouse/init:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8123/ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    ulimits:
      nofile:
        soft: 262144
        hard: 262144

  # ==========================================================================
  # Aerospike - Feature Store (Aggregated Features for Real-time Inference)
  # Note: Will be populated by aggregation pipeline from ClickHouse
  # ==========================================================================
  aerospike:
    image: aerospike/aerospike-server:7.0.0.0
    container_name: dataplatform-aerospike
    ports:
      - "3010:3000"
      - "3011:3001"
      - "3012:3002"
    volumes:
      - dataplatform_aerospike_data:/opt/aerospike/data
    healthcheck:
      test: ["CMD", "asinfo", "-v", "status"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ==========================================================================
  # Feature Materializer - Kafka to ClickHouse
  # Consumes from all event topics and writes raw events to ClickHouse
  # ==========================================================================
  feature-materializer:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: dataplatform-feature-materializer
    command: ["python", "-m", "runtime.ingestion.feature_materializer"]
    depends_on:
      kafka:
        condition: service_healthy
      clickhouse:
        condition: service_healthy
    ports:
      - "8012:8011"  # Health check endpoint (different port for prod)
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      CLICKHOUSE_HOST: clickhouse
      CLICKHOUSE_PORT: "8123"
      CLICKHOUSE_USER: cartnudge
      CLICKHOUSE_PASSWORD: cartnudge_dev
      CLICKHOUSE_DATABASE: events
      HEALTH_CHECK_PORT: "8011"
      PYTHONUNBUFFERED: "1"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8011/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
    profiles:
      - materializer

  # ==========================================================================
  # Feature Materializer - Development (always on, no profile needed)
  # ==========================================================================
  feature-materializer-dev:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: dataplatform-feature-materializer-dev
    command: ["python", "-m", "runtime.ingestion.feature_materializer"]
    depends_on:
      kafka:
        condition: service_healthy
      clickhouse:
        condition: service_healthy
    ports:
      - "8011:8011"  # Health check endpoint
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      CLICKHOUSE_HOST: clickhouse
      CLICKHOUSE_PORT: "8123"
      CLICKHOUSE_USER: cartnudge
      CLICKHOUSE_PASSWORD: cartnudge_dev
      CLICKHOUSE_DATABASE: events
      HEALTH_CHECK_PORT: "8011"
      PYTHONUNBUFFERED: "1"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8011/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "2"

  # ==========================================================================
  # Development Tools
  # ==========================================================================
  kafka-ui:
    image: provectuslabs/kafka-ui:v0.7.1
    container_name: dataplatform-kafka-ui
    depends_on:
      - kafka
    ports:
      - "8084:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
    profiles:
      - tools

volumes:
  dataplatform_mongodb_data:
  dataplatform_kafka_data:
  dataplatform_clickhouse_data:
  dataplatform_aerospike_data:
